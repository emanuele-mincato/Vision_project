{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Vision_project.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Vision and Cognitive Services Project\n",
        "## Understanding clouds from satellite images\n",
        "\n",
        "Climate change has been at the top of our minds and on the forefront of important political decision-making for many years. Shallow clouds play a huge role in determining the Earth's climate. Theyâ€™re also difficult to understand and to represent in climate models.\n",
        "In this project, we will build a model to classify cloud organization patterns from satellite images."
      ],
      "metadata": {
        "id": "SxlUyDPmx28z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is composed by 5546 images for the training set and 3698 images for the test one. For each image we have the run length encoded segmentations that mark the region of the cloud. We have to classify four different classes of clouds:\n",
        "\n",
        "- Fish\n",
        "- Flower\n",
        "- Gravel \n",
        "- Sugar \n",
        "\n",
        "The goal is to predict the segmentation masks of each of the 4 cloud types for each image in the test set. \n"
      ],
      "metadata": {
        "id": "hAfj-lNpx285"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import gc\n",
        "import cv2\n",
        "from glob import glob\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import patches as patches\n",
        "# plotly offline imports\n",
        "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
        "from plotly import subplots\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.graph_objs import *\n",
        "from plotly.graph_objs.layout import Margin, YAxis, XAxis\n",
        "init_notebook_mode()\n",
        "# frequent pattern mining\n",
        "from mlxtend.frequent_patterns import fpgrowth\n",
        "# import image manipulation\n",
        "from PIL import Image\n",
        "import imageio\n",
        "import albumentations as albu\n",
        "from albumentations import pytorch as AT\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tqdm\n",
        "from tqdm.auto import tqdm as tq\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:07.115055Z",
          "iopub.execute_input": "2021-09-11T12:39:07.115388Z",
          "iopub.status.idle": "2021-09-11T12:39:12.332699Z",
          "shell.execute_reply.started": "2021-09-11T12:39:07.115324Z",
          "shell.execute_reply": "2021-09-11T12:39:12.331347Z"
        },
        "trusted": true,
        "id": "Ba8JEIazx285"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper function"
      ],
      "metadata": {
        "id": "Fchs81T8x287"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img(x, folder: str='train_images'):\n",
        "    \"\"\"\n",
        "    Return image based on image name and folder.\n",
        "    \"\"\"\n",
        "    data_folder = f\"{DATA_PATH}/{folder}\"\n",
        "    image_path = os.path.join(data_folder, x)\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "def plot_with_augmentation(image, mask, augment):\n",
        "    \"\"\"\n",
        "    Wrapper for `visualize` function.\n",
        "    \"\"\"\n",
        "    augmented = augment(image=image, mask=mask)\n",
        "    image_flipped = augmented['image']\n",
        "    mask_flipped = augmented['mask']\n",
        "    visualize(image_flipped, mask_flipped, original_image=image, original_mask=mask)\n",
        "\n",
        "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
        "\n",
        "def post_process(probability, threshold, min_size):\n",
        "    \"\"\"\n",
        "    Post processing of each predicted mask, components with lesser number of pixels\n",
        "    than `min_size` are ignored\n",
        "    \"\"\"\n",
        "    # don't remember where I saw it\n",
        "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
        "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
        "    predictions = np.zeros((350, 525), np.float32)\n",
        "    num = 0\n",
        "    for c in range(1, num_component):\n",
        "        p = (component == c)\n",
        "        if p.sum() > min_size:\n",
        "            predictions[p] = 1\n",
        "            num += 1\n",
        "    return predictions, num\n",
        "\n",
        "    \n",
        "# helper function to get a string of labels for the picture\n",
        "def get_labels(image_id):\n",
        "    ''' Function to get the labels for the image by name'''\n",
        "    im_df = train_df[train_df['ImageId'] == image_id]\n",
        "    im_df = im_df[im_df['EncodedPixels'] != -1].groupby('Label').count()    \n",
        "    index = im_df.index\n",
        "    all_labels = ['Fish', 'Flower', 'Gravel', 'Sugar']\n",
        "    \n",
        "    labels = ''\n",
        "    \n",
        "    for label in all_labels:\n",
        "        if label in index:\n",
        "            labels = labels + ' ' + label\n",
        "    \n",
        "    return labels\n",
        "\n",
        "def make_mask(df: pd.DataFrame ,image_name: str='img.jpg', shape: tuple = (350, 525)):\n",
        "    \"\"\"\n",
        "    Create mask based on df, image name and shape.\n",
        "    \"\"\"\n",
        "    masks = np.zeros((shape[0], shape[1], 4), dtype=np.float32)\n",
        "    df = df[df[\"im_id\"] == image_name]\n",
        "    for idx, im_name in enumerate(df[\"im_id\"].values):\n",
        "        for classidx, classid in enumerate([\"Fish\", \"Flower\", \"Gravel\", \"Sugar\"]):\n",
        "            mask = cv2.imread(\"../input/understanding-clouds-resized/train_masks_525/train_masks_525/\" + classid + im_name)\n",
        "            if mask is None:\n",
        "                continue\n",
        "            if mask[:,:,0].shape != (350,525):\n",
        "                mask = cv2.resize(mask, (525,350))\n",
        "            masks[:, :, classidx] = mask[:,:,0]\n",
        "    masks = masks/255\n",
        "    return masks\n",
        "\n",
        "# seeding function for reproducibility\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "def resize_it(x):\n",
        "    if x.shape != (350, 525):\n",
        "        x = cv2.resize(x, dsize=(525, 350), interpolation=cv2.INTER_LINEAR)\n",
        "    return x\n",
        "\n",
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "        albu.HorizontalFlip(p=0.5), # p=0 no augmentation # p=1 all imges augmented\n",
        "        albu.VerticalFlip(p=0.5),\n",
        "        albu.ElasticTransform(p=0.5, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
        "        albu.RandomRotate90(p=0.5),\n",
        "        #albu.GridDistortion(p=0.5),\n",
        "        albu.Resize(320, 640),\n",
        "        albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ]\n",
        "    return albu.Compose(train_transform)\n",
        "\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "    test_transform = [\n",
        "        albu.Resize(320, 640),\n",
        "        albu.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    ]\n",
        "    return albu.Compose(test_transform)\n",
        "\n",
        "def mask2rle(img):\n",
        "    \"\"\"\n",
        "    Convert mask to rle.\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    \"\"\"\n",
        "    pixels = img.T.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return \" \".join(str(x) for x in runs)\n",
        "\n",
        "def dice(img1, img2):\n",
        "    img1 = np.asarray(img1).astype(np.bool)\n",
        "    img2 = np.asarray(img2).astype(np.bool)\n",
        "\n",
        "    intersection = np.logical_and(img1, img2)\n",
        "\n",
        "    return 2.0 * intersection.sum() / (img1.sum() + img2.sum())\n",
        "\n",
        "def dice_no_threshold(\n",
        "    outputs: torch.Tensor,\n",
        "    targets: torch.Tensor,\n",
        "    eps: float = 1e-7,\n",
        "    threshold: float = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Reference:\n",
        "    https://catalyst-team.github.io/catalyst/_modules/catalyst/dl/utils/criterion/dice.html\n",
        "    \"\"\"\n",
        "    if threshold is not None:\n",
        "        outputs = (outputs > threshold).float()\n",
        "\n",
        "    intersection = torch.sum(targets * outputs)\n",
        "    union = torch.sum(targets) + torch.sum(outputs)\n",
        "    dice = 2 * intersection / (union + eps)\n",
        "\n",
        "    return dice\n",
        "\n",
        "def visualize_with_raw(\n",
        "    image, mask, original_image=None, original_mask=None, raw_image=None, raw_mask=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot image and masks.\n",
        "    If two pairs of images and masks are passes, show both.\n",
        "    \"\"\"\n",
        "    fontsize = 14\n",
        "    class_dict = {0: \"Fish\", 1: \"Flower\", 2: \"Gravel\", 3: \"Sugar\"}\n",
        "\n",
        "    f, ax = plt.subplots(3, 5, figsize=(24, 12))\n",
        "\n",
        "    ax[0, 0].imshow(original_image)\n",
        "    ax[0, 0].set_title(\"Original image\", fontsize=fontsize)\n",
        "\n",
        "    for i in range(4):\n",
        "        ax[0, i + 1].imshow(original_mask[:, :, i])\n",
        "        ax[0, i + 1].set_title(f\"Original mask {class_dict[i]}\", fontsize=fontsize)\n",
        "\n",
        "    ax[1, 0].imshow(raw_image)\n",
        "    ax[1, 0].set_title(\"Original image\", fontsize=fontsize)\n",
        "\n",
        "    for i in range(4):\n",
        "        ax[1, i + 1].imshow(raw_mask[:, :, i])\n",
        "        ax[1, i + 1].set_title(f\"Raw predicted mask {class_dict[i]}\", fontsize=fontsize)\n",
        "\n",
        "    ax[2, 0].imshow(image)\n",
        "    ax[2, 0].set_title(\"Transformed image\", fontsize=fontsize)\n",
        "\n",
        "    for i in range(4):\n",
        "        ax[2, i + 1].imshow(mask[:, :, i])\n",
        "        ax[2, i + 1].set_title(\n",
        "            f\"Predicted mask with processing {class_dict[i]}\", fontsize=fontsize\n",
        "        )\n",
        "\n",
        "\n",
        "def visualize(image, mask, original_image=None, original_mask=None):\n",
        "    \"\"\"\n",
        "    Plot image and masks.\n",
        "    If two pairs of images and masks are passes, show both.\n",
        "    \"\"\"\n",
        "    fontsize = 14\n",
        "    class_dict = {0: 'Fish', 1: 'Flower', 2: 'Gravel', 3: 'Sugar'}\n",
        "    \n",
        "    if original_image is None and original_mask is None:\n",
        "        f, ax = plt.subplots(1, 5, figsize=(24, 24))\n",
        "\n",
        "        ax[0].imshow(image)\n",
        "        for i in range(4):\n",
        "            ax[i + 1].imshow(mask[:, :, i])\n",
        "            ax[i + 1].set_title(f'Mask {class_dict[i]}', fontsize=fontsize)\n",
        "    else:\n",
        "        f, ax = plt.subplots(2, 5, figsize=(24, 12))\n",
        "\n",
        "        ax[0, 0].imshow(original_image)\n",
        "        ax[0, 0].set_title('Original image', fontsize=fontsize)\n",
        "                \n",
        "        for i in range(4): \n",
        "            ax[0, i + 1].imshow(original_mask[:, :, i])\n",
        "            ax[0, i + 1].set_title(f'Original mask {class_dict[i]}', fontsize=fontsize)\n",
        "        \n",
        "        ax[1, 0].imshow(image)\n",
        "        ax[1, 0].set_title('Transformed image', fontsize=fontsize)\n",
        "        \n",
        "        \n",
        "        for i in range(4):\n",
        "            ax[1, i + 1].imshow(mask[:, :, i])\n",
        "            ax[1, i + 1].set_title(f'Transformed mask {class_dict[i]}', fontsize=fontsize)\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:12.335339Z",
          "iopub.execute_input": "2021-09-11T12:39:12.335675Z",
          "iopub.status.idle": "2021-09-11T12:39:12.394978Z",
          "shell.execute_reply.started": "2021-09-11T12:39:12.335611Z",
          "shell.execute_reply": "2021-09-11T12:39:12.393435Z"
        },
        "trusted": true,
        "id": "A8Avflxzx288"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '../input/understanding_cloud_organization' \n",
        "TRAIN_CSV_PATH = os.path.join(DATA_PATH,'train.csv')\n",
        "TRAIN_IMAGE_PATH = os.path.join(DATA_PATH,'train_images')\n",
        "SEED = 42\n",
        "MODEL_NO = 0 # in K-fold\n",
        "N_FOLDS = 10 # in K-fold\n",
        "train_on_gpu = torch.cuda.is_available()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:12.397189Z",
          "iopub.execute_input": "2021-09-11T12:39:12.397677Z",
          "iopub.status.idle": "2021-09-11T12:39:12.461119Z",
          "shell.execute_reply.started": "2021-09-11T12:39:12.397594Z",
          "shell.execute_reply": "2021-09-11T12:39:12.459394Z"
        },
        "trusted": true,
        "id": "PPmWAOWax28-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.read_csv(TRAIN_CSV_PATH).head()"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:12.463317Z",
          "iopub.execute_input": "2021-09-11T12:39:12.46375Z",
          "iopub.status.idle": "2021-09-11T12:39:16.725537Z",
          "shell.execute_reply.started": "2021-09-11T12:39:12.463641Z",
          "shell.execute_reply": "2021-09-11T12:39:16.724726Z"
        },
        "trusted": true,
        "id": "9hsSS_VMx28_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load full data and label no mask as -1\n",
        "train_df = pd.read_csv(TRAIN_CSV_PATH).fillna(-1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:16.730337Z",
          "iopub.execute_input": "2021-09-11T12:39:16.730612Z",
          "iopub.status.idle": "2021-09-11T12:39:19.562364Z",
          "shell.execute_reply.started": "2021-09-11T12:39:16.730556Z",
          "shell.execute_reply": "2021-09-11T12:39:19.560961Z"
        },
        "trusted": true,
        "id": "HB73TMAQx29A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image id and class id are two seperate entities and it makes it easier to split them up in two columns\n",
        "train_df['ImageId'] = train_df['Image_Label'].apply(lambda x: x.split('_')[0])\n",
        "train_df['Label'] = train_df['Image_Label'].apply(lambda x: x.split('_')[1])\n",
        "# lets create a dict with class id and encoded pixels and group all the defaults per image\n",
        "train_df['Label_EncodedPixels'] = train_df.apply(lambda row: (row['Label'], row['EncodedPixels']), axis = 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:19.571862Z",
          "iopub.execute_input": "2021-09-11T12:39:19.572239Z",
          "iopub.status.idle": "2021-09-11T12:39:20.370824Z",
          "shell.execute_reply.started": "2021-09-11T12:39:19.572173Z",
          "shell.execute_reply": "2021-09-11T12:39:20.369754Z"
        },
        "trusted": true,
        "id": "2P6hURWCx29A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total number of images: %s' % len(train_df['ImageId'].unique()))\n",
        "print('Images with at least one label: %s' % len(train_df[train_df['EncodedPixels'] != 'NaN']['ImageId'].unique()))\n",
        "print('Total instance or examples of defects: %s' % len(train_df[train_df['EncodedPixels'] != 'NaN']))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:20.372682Z",
          "iopub.execute_input": "2021-09-11T12:39:20.373077Z",
          "iopub.status.idle": "2021-09-11T12:39:20.406784Z",
          "shell.execute_reply.started": "2021-09-11T12:39:20.373004Z",
          "shell.execute_reply": "2021-09-11T12:39:20.40544Z"
        },
        "trusted": true,
        "id": "XcOFORYFx29B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different Types of Clouds\n",
        "\n",
        "The first important thing I want to understand are the followings:\n",
        "1. What are the different types of clouds we have in our dataset.\n",
        "2. How does the mask for these formation looks like.\n",
        "2. Value cout of how many types of clouds we have per image.\n",
        "3. Distribution / frequency of each types of clouds in our dataset."
      ],
      "metadata": {
        "id": "9q1stmw4x29C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# different types of clouds we have in our dataset\n",
        "train_df['Label'].unique()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:20.408527Z",
          "iopub.execute_input": "2021-09-11T12:39:20.409094Z",
          "iopub.status.idle": "2021-09-11T12:39:20.418793Z",
          "shell.execute_reply.started": "2021-09-11T12:39:20.408816Z",
          "shell.execute_reply": "2021-09-11T12:39:20.41725Z"
        },
        "trusted": true,
        "id": "DSqn3tBox29C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pot a grid of images and their labels\n",
        "images_path = TRAIN_IMAGE_PATH+'/'\n",
        "images = sorted(glob(images_path + '*.jpg'))\n",
        "width = 5\n",
        "height = 3\n",
        "\n",
        "fig, axs = plt.subplots(height, width, figsize=(width * 3, height * 3))\n",
        "    \n",
        "# create a list of random indices \n",
        "rnd_indices = [np.random.choice(range(0, len(images))) for i in range(height * width)]\n",
        "\n",
        "for im in range(0, height * width):\n",
        "    # open image with a random index\n",
        "    image = Image.open(images[rnd_indices[im]])\n",
        "\n",
        "    i = im // width\n",
        "    j = im % width\n",
        "\n",
        "    # plot the image\n",
        "    axs[i,j].imshow(image) #plot the data\n",
        "    axs[i,j].axis('off')\n",
        "    axs[i,j].set_title(get_labels(images[rnd_indices[im]].split('/')[-1]))\n",
        "\n",
        "# set suptitle\n",
        "plt.suptitle('Sample images from the train set')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:20.421344Z",
          "iopub.execute_input": "2021-09-11T12:39:20.42199Z",
          "iopub.status.idle": "2021-09-11T12:39:25.827915Z",
          "shell.execute_reply.started": "2021-09-11T12:39:20.421745Z",
          "shell.execute_reply": "2021-09-11T12:39:25.826988Z"
        },
        "trusted": true,
        "id": "_hUQ4eeIx29D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets group each of the types and their mask in a list so we can do more aggregated counts\n",
        "grouped_EncodedPixels = train_df.groupby('ImageId')['Label_EncodedPixels'].apply(list)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:25.82947Z",
          "iopub.execute_input": "2021-09-11T12:39:25.830017Z",
          "iopub.status.idle": "2021-09-11T12:39:26.495262Z",
          "shell.execute_reply.started": "2021-09-11T12:39:25.829931Z",
          "shell.execute_reply": "2021-09-11T12:39:26.49431Z"
        },
        "trusted": true,
        "id": "8kkCRvlwx29D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.fillna(-1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:26.497481Z",
          "iopub.execute_input": "2021-09-11T12:39:26.498118Z",
          "iopub.status.idle": "2021-09-11T12:39:26.520798Z",
          "shell.execute_reply.started": "2021-09-11T12:39:26.497838Z",
          "shell.execute_reply": "2021-09-11T12:39:26.519953Z"
        },
        "trusted": true,
        "id": "Jt6DxrIpx29D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of labels per image has\n",
        "labels_per_image_count = grouped_EncodedPixels.apply(lambda x: len([x[0] for x in x if x[1]!=-1])).value_counts()\n",
        "# count frequency of each type of cloud\n",
        "label_type_per_image = train_df[train_df['EncodedPixels']!=-1]['Label'].value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:26.523378Z",
          "iopub.execute_input": "2021-09-11T12:39:26.524155Z",
          "iopub.status.idle": "2021-09-11T12:39:26.555194Z",
          "shell.execute_reply.started": "2021-09-11T12:39:26.523737Z",
          "shell.execute_reply": "2021-09-11T12:39:26.554304Z"
        },
        "trusted": true,
        "id": "sHRjEgHBx29E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we have the data ready lets plot them to answer our questions\n",
        "trace0 = Bar(x=labels_per_image_count.index, y=labels_per_image_count.values, name = 'Number of Cloud Types Per Image')\n",
        "trace1 = Bar(x=label_type_per_image.index, y=label_type_per_image.values, name = 'Frequency of Different Clouds')\n",
        "fig = subplots.make_subplots(rows=1, cols=2)\n",
        "fig.append_trace(trace0, 1, 1)\n",
        "fig.append_trace(trace1, 1, 2)\n",
        "fig['layout'].update(height=400, width=900, title='Label Count and Frequency Per Image')\n",
        "iplot(fig)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:26.55726Z",
          "iopub.execute_input": "2021-09-11T12:39:26.557797Z",
          "iopub.status.idle": "2021-09-11T12:39:28.254701Z",
          "shell.execute_reply.started": "2021-09-11T12:39:26.557685Z",
          "shell.execute_reply": "2021-09-11T12:39:28.253758Z"
        },
        "trusted": true,
        "id": "1NjSuTMOx29E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('There are {} fish clouds'.format(label_type_per_image['Fish']))\n",
        "print('There are {} flower clouds'.format(label_type_per_image['Flower']))\n",
        "print('There are {} gravel clouds'.format(label_type_per_image['Gravel']))\n",
        "print('There are {} sugar clouds'.format(label_type_per_image['Sugar']))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:28.256332Z",
          "iopub.execute_input": "2021-09-11T12:39:28.257155Z",
          "iopub.status.idle": "2021-09-11T12:39:28.266843Z",
          "shell.execute_reply.started": "2021-09-11T12:39:28.257096Z",
          "shell.execute_reply": "2021-09-11T12:39:28.264998Z"
        },
        "trusted": true,
        "id": "hJ2Cb-urx29E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('There are {} images with one type of clouds'.format(labels_per_image_count[1]))\n",
        "print('There are {} images with two type of clouds'.format(labels_per_image_count[2]))\n",
        "print('There are {} images with three type of clouds'.format(labels_per_image_count[3]))\n",
        "print('There are {}  images with four type of clouds'.format(labels_per_image_count[4]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:28.269268Z",
          "iopub.execute_input": "2021-09-11T12:39:28.270044Z",
          "iopub.status.idle": "2021-09-11T12:39:28.281855Z",
          "shell.execute_reply.started": "2021-09-11T12:39:28.269736Z",
          "shell.execute_reply": "2021-09-11T12:39:28.280714Z"
        },
        "trusted": true,
        "id": "-eTmb3c7x29F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like most of the time we have 2-3 types of cloud formation in one image. 4 types of cloud formation in one image is very rare. Only one type of cloud formation in the image is also somewhat common. Furthermore, the data looks very evenly distributed for all four types of cloud formation. "
      ],
      "metadata": {
        "id": "thOMulfBx29F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drawing Clouds\n",
        "\n",
        "Now we know a little bit about the distribution of our data, we need to take a look at it and get an understanding of what it's all about. First, the masks are encoded so we will need the following function to decode the mask."
      ],
      "metadata": {
        "id": "1VquoLB5x29F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rle_to_mask(rle_string, height, width):\n",
        "    '''\n",
        "    convert RLE(run length encoding) string to numpy array\n",
        "\n",
        "    Parameters: \n",
        "    rle_string (str): string of rle encoded mask\n",
        "    height (int): height of the mask\n",
        "    width (int): width of the mask \n",
        "\n",
        "    Returns: \n",
        "    numpy.array: numpy array of the mask\n",
        "    '''\n",
        "    \n",
        "    rows, cols = height, width\n",
        "    \n",
        "    if rle_string == -1:\n",
        "        return np.zeros((height, width))\n",
        "    else:\n",
        "        rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n",
        "        rle_pairs = np.array(rle_numbers).reshape(-1,2)\n",
        "        img = np.zeros(rows*cols, dtype=np.uint8)\n",
        "        for index, length in rle_pairs:\n",
        "            index -= 1\n",
        "            img[index:index+length] = 255\n",
        "        img = img.reshape(cols,rows)\n",
        "        img = img.T\n",
        "        return img\n",
        "    \n",
        "def rle_decode(mask_rle: str = '', shape: tuple = (1400, 2100)):\n",
        "    '''\n",
        "    Decode rle encoded mask.\n",
        "    \n",
        "    :param mask_rle: run-length as string formatted (start length)\n",
        "    :param shape: (height, width) of array to return \n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape, order='F')"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:28.283965Z",
          "iopub.execute_input": "2021-09-11T12:39:28.284658Z",
          "iopub.status.idle": "2021-09-11T12:39:28.303435Z",
          "shell.execute_reply.started": "2021-09-11T12:39:28.284581Z",
          "shell.execute_reply": "2021-09-11T12:39:28.302339Z"
        },
        "trusted": true,
        "id": "CcPi6SEfx29F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets just plot a single image and a mask to get an idea of what it looks like."
      ],
      "metadata": {
        "id": "9HGIGPsqx29G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(os.path.join(TRAIN_IMAGE_PATH, train_df['ImageId'][0]))\n",
        "mask_decoded = rle_to_mask(train_df['Label_EncodedPixels'][0][1], img.shape[0], img.shape[1])\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(20,10))\n",
        "ax[0].imshow(img)\n",
        "ax[1].imshow(mask_decoded)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:28.30619Z",
          "iopub.execute_input": "2021-09-11T12:39:28.306514Z",
          "iopub.status.idle": "2021-09-11T12:39:29.384782Z",
          "shell.execute_reply.started": "2021-09-11T12:39:28.306451Z",
          "shell.execute_reply": "2021-09-11T12:39:29.378205Z"
        },
        "trusted": true,
        "id": "Nc-MMKAjx29G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it seems, there are images of clouds, and a mask not outlining the exact clouds but roughly the area with the same kind of patterns. And from our last section, we know an image can have more than one type of cloud patterns. So, I propose we visualize an image in two columns. First, shows the different types of cloud formation with a bounding box. On the second column, we visualize the cloud picture with the mask segments as an overlay."
      ],
      "metadata": {
        "id": "8Da_Kxxex29G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bounding_box(img):\n",
        "    # return max and min of a mask to draw bounding box\n",
        "    rows = np.any(img, axis=1)\n",
        "    cols = np.any(img, axis=0)\n",
        "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
        "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
        "\n",
        "    return rmin, rmax, cmin, cmax"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:29.387229Z",
          "iopub.execute_input": "2021-09-11T12:39:29.387872Z",
          "iopub.status.idle": "2021-09-11T12:39:29.397894Z",
          "shell.execute_reply.started": "2021-09-11T12:39:29.387513Z",
          "shell.execute_reply": "2021-09-11T12:39:29.396409Z"
        },
        "trusted": true,
        "id": "yfbAVcHex29G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cloud(img_path, img_id, label_mask):\n",
        "    img = cv2.imread(os.path.join(img_path, img_id))\n",
        "    \n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, sharey=False, figsize=(20,10))\n",
        "    ax[0].imshow(img)\n",
        "    ax[1].imshow(img)\n",
        "    cmaps = {'Fish': 'Blues', 'Flower': 'Reds', 'Gravel': 'Greens', 'Sugar':'Purples'}\n",
        "    colors = {'Fish': 'Blue', 'Flower': 'Red', 'Gravel': 'Green', 'Sugar':'Purple'}\n",
        "    for label, mask in label_mask:\n",
        "        mask_decoded = rle_to_mask(mask, img.shape[0], img.shape[1])\n",
        "        if mask != -1:\n",
        "            rmin, rmax, cmin, cmax = bounding_box(mask_decoded)\n",
        "            bbox = patches.Rectangle((cmin,rmin),cmax-cmin,rmax-rmin,linewidth=1,edgecolor=colors[label],facecolor='none')\n",
        "            ax[0].add_patch(bbox)\n",
        "            ax[0].text(cmin, rmin, label, bbox=dict(fill=True, color=colors[label]))\n",
        "            ax[1].imshow(mask_decoded, alpha=0.3, cmap=cmaps[label])\n",
        "            ax[0].text(cmin, rmin, label, bbox=dict(fill=True, color=colors[label]))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:29.400573Z",
          "iopub.execute_input": "2021-09-11T12:39:29.401529Z",
          "iopub.status.idle": "2021-09-11T12:39:29.419372Z",
          "shell.execute_reply.started": "2021-09-11T12:39:29.401023Z",
          "shell.execute_reply": "2021-09-11T12:39:29.417942Z"
        },
        "trusted": true,
        "id": "XQ3-EbK0x29H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets print out 10 random samples!"
      ],
      "metadata": {
        "id": "wwgHq0Kix29H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image_id, label_mask in grouped_EncodedPixels.sample(10).iteritems():\n",
        "    plot_cloud(TRAIN_IMAGE_PATH, image_id, label_mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:29.422053Z",
          "iopub.execute_input": "2021-09-11T12:39:29.422546Z",
          "iopub.status.idle": "2021-09-11T12:39:45.034699Z",
          "shell.execute_reply.started": "2021-09-11T12:39:29.422376Z",
          "shell.execute_reply": "2021-09-11T12:39:45.033183Z"
        },
        "trusted": true,
        "id": "tL2wJt3wx29H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '../input/understanding_cloud_organization'\n",
        "train = pd.read_csv(TRAIN_CSV_PATH)\n",
        "train['Image_Label'].apply(lambda x: x.split('_')[1]).value_counts()\n",
        "train.loc[train['EncodedPixels'].isnull() == False, 'Image_Label'].apply(lambda x: x.split('_')[1]).value_counts()\n",
        "train.loc[train['EncodedPixels'].isnull() == False, 'Image_Label'].apply(lambda x: x.split('_')[0]).value_counts().value_counts()\n",
        "train['label'] = train['Image_Label'].apply(lambda x: x.split('_')[1])\n",
        "train['im_id'] = train['Image_Label'].apply(lambda x: x.split('_')[0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:45.036807Z",
          "iopub.execute_input": "2021-09-11T12:39:45.037367Z",
          "iopub.status.idle": "2021-09-11T12:39:47.64495Z",
          "shell.execute_reply.started": "2021-09-11T12:39:45.037139Z",
          "shell.execute_reply": "2021-09-11T12:39:47.643954Z"
        },
        "trusted": true,
        "id": "MEF75ysAx29H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(25, 16))\n",
        "for j, im_id in enumerate(np.random.choice(train['im_id'].unique(), 4)):\n",
        "    for i, (idx, row) in enumerate(train.loc[train['im_id'] == im_id].iterrows()):\n",
        "        ax = fig.add_subplot(5, 4, j * 4 + i + 1, xticks=[], yticks=[])\n",
        "        im = Image.open(f\"{path}/train_images/{row['Image_Label'].split('_')[0]}\")\n",
        "        plt.imshow(im)\n",
        "        mask_rle = row['EncodedPixels']\n",
        "        \n",
        "        try: # label might not be there!\n",
        "            mask = rle_decode(mask_rle)\n",
        "        except:\n",
        "            mask = np.zeros((1400, 2100))\n",
        "        plt.imshow(mask, alpha=0.5, cmap='gray')\n",
        "        ax.set_title(f\"Image: {row['Image_Label'].split('_')[0]}. Label: {row['label']}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:47.646797Z",
          "iopub.execute_input": "2021-09-11T12:39:47.647182Z",
          "iopub.status.idle": "2021-09-11T12:39:55.262686Z",
          "shell.execute_reply.started": "2021-09-11T12:39:47.64712Z",
          "shell.execute_reply": "2021-09-11T12:39:55.261105Z"
        },
        "trusted": true,
        "id": "U115MwG2x29H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zooming In To The Cloud Formations\n",
        "\n",
        "In the last section, we visualized many types of cloud formation at once. This visualization is good as it gives us a good high level picture of our training images. Also, excuse me for the terrible pun. However, in this section we will zoom into the different type of cloud formations by using the mask to mute out the section that doesn't belong to the type of cloud formation we are interested in. Our main question for this section is the following:\n",
        "\n",
        "* How do different types of cloud formations look like to the naked eye."
      ],
      "metadata": {
        "id": "n7e55_Izx29H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mask_cloud(img_path, img_id, label, mask):\n",
        "    img = cv2.imread(os.path.join(img_path, img_id), 0)\n",
        "    mask_decoded = rle_to_mask(mask, img.shape[0], img.shape[1])\n",
        "    mask_decoded = (mask_decoded > 0.0).astype(int)\n",
        "    img = np.multiply(img, mask_decoded)\n",
        "    return img"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:55.265146Z",
          "iopub.execute_input": "2021-09-11T12:39:55.265723Z",
          "iopub.status.idle": "2021-09-11T12:39:55.275106Z",
          "shell.execute_reply.started": "2021-09-11T12:39:55.265417Z",
          "shell.execute_reply": "2021-09-11T12:39:55.273493Z"
        },
        "trusted": true,
        "id": "DH8u7dmVx29I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_label_only(label):\n",
        "    samples_df = train_df[(train_df['EncodedPixels']!=-1) & (train_df['Label']==label)].sample(2)\n",
        "    count = 0\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(20,10))\n",
        "    for idx, sample in samples_df.iterrows():\n",
        "        img = get_mask_cloud(TRAIN_IMAGE_PATH, sample['ImageId'], sample['Label'],sample['EncodedPixels'])\n",
        "        ax[count].imshow(img, cmap=\"gray\")\n",
        "        count += 1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:55.277214Z",
          "iopub.execute_input": "2021-09-11T12:39:55.278139Z",
          "iopub.status.idle": "2021-09-11T12:39:55.290641Z",
          "shell.execute_reply.started": "2021-09-11T12:39:55.277833Z",
          "shell.execute_reply": "2021-09-11T12:39:55.289512Z"
        },
        "trusted": true,
        "id": "4odYDs_tx29I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fish Cloud Formation"
      ],
      "metadata": {
        "id": "9_2xteaGx29I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draw_label_only('Fish')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:55.293128Z",
          "iopub.execute_input": "2021-09-11T12:39:55.293841Z",
          "iopub.status.idle": "2021-09-11T12:39:56.607528Z",
          "shell.execute_reply.started": "2021-09-11T12:39:55.293445Z",
          "shell.execute_reply": "2021-09-11T12:39:56.606581Z"
        },
        "trusted": true,
        "id": "ljDhzeCnx29I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Flower Cloud Formation"
      ],
      "metadata": {
        "id": "hiyvdqcnx29I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draw_label_only('Flower')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:56.609067Z",
          "iopub.execute_input": "2021-09-11T12:39:56.609658Z",
          "iopub.status.idle": "2021-09-11T12:39:58.084152Z",
          "shell.execute_reply.started": "2021-09-11T12:39:56.609566Z",
          "shell.execute_reply": "2021-09-11T12:39:58.083048Z"
        },
        "trusted": true,
        "id": "l_TzMxtux29J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gravel Cloud Formation"
      ],
      "metadata": {
        "id": "LcsfMkDWx29J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draw_label_only('Gravel')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:58.08575Z",
          "iopub.execute_input": "2021-09-11T12:39:58.086279Z",
          "iopub.status.idle": "2021-09-11T12:39:59.295367Z",
          "shell.execute_reply.started": "2021-09-11T12:39:58.08622Z",
          "shell.execute_reply": "2021-09-11T12:39:59.294427Z"
        },
        "trusted": true,
        "id": "SCYEoj07x29J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sugar Cloud Formation"
      ],
      "metadata": {
        "id": "2zcZMDY8x29J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "draw_label_only('Sugar')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:39:59.297218Z",
          "iopub.execute_input": "2021-09-11T12:39:59.297767Z",
          "iopub.status.idle": "2021-09-11T12:40:00.484868Z",
          "shell.execute_reply.started": "2021-09-11T12:39:59.297709Z",
          "shell.execute_reply": "2021-09-11T12:40:00.483791Z"
        },
        "trusted": true,
        "id": "T_8f7mQvx29J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, I sort of get the sense why the cloud formations are called what they are called. What I am afraid of is often times, it seems like there is a little bit of cloud formation from one type overlaps with cloud formation of another type. I am interested to see how our algorithm performs in these scenarios."
      ],
      "metadata": {
        "id": "ix7l-3DXx29J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloud That Forms Together Stays Together\n",
        "As we saw in the previous visualizations, it's very common for multiple cloud formations to be present in a single image. In this section we want to answer:\n",
        "1. Which cloud formations occur frequently.\n",
        "2. Which cloud formations hardly ever appears together.\n",
        "\n",
        "To do this, we will use a really simple data mining algorithm called Frequent Pattern Mining. FP Growth is a particular algorithmic implementation of Frequent Pattern, which aims to identify items that appear frequently together in a list. "
      ],
      "metadata": {
        "id": "zQFvH1ahx29J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a series with fault classes\n",
        "label_per_image = grouped_EncodedPixels.apply(lambda encoded_list: [x[0] for x in encoded_list if x[1] != -1])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:40:00.487048Z",
          "iopub.execute_input": "2021-09-11T12:40:00.487658Z",
          "iopub.status.idle": "2021-09-11T12:40:00.507547Z",
          "shell.execute_reply.started": "2021-09-11T12:40:00.487571Z",
          "shell.execute_reply": "2021-09-11T12:40:00.506529Z"
        },
        "trusted": true,
        "id": "waZ9-Tm_x29K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of dict with count of each fault class\n",
        "label_per_image_list = []\n",
        "for r in label_per_image.iteritems():\n",
        "    label_count = {'Fish':0,'Flower':0,'Gravel':0,'Sugar':0}\n",
        "    # go over each class and \n",
        "    for image_label in r[1]:\n",
        "        label_count[image_label] = 1\n",
        "    label_per_image_list.append(label_count)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:40:00.510045Z",
          "iopub.execute_input": "2021-09-11T12:40:00.510513Z",
          "iopub.status.idle": "2021-09-11T12:40:00.526304Z",
          "shell.execute_reply.started": "2021-09-11T12:40:00.51042Z",
          "shell.execute_reply": "2021-09-11T12:40:00.524739Z"
        },
        "trusted": true,
        "id": "hlegXKIHx29K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do FP calculation with all image\n",
        "label_per_image_df = pd.DataFrame(label_per_image_list)\n",
        "label_fp_df = fpgrowth(label_per_image_df, use_colnames=True, min_support=0.001)\n",
        "label_fp_df = label_fp_df.sort_values(by=['support'])\n",
        "label_combi_fp_df = label_fp_df[label_fp_df['itemsets'].apply(lambda x: len(x) > 1)]\n",
        "label_combi_fp_df['itemsets'] = label_combi_fp_df['itemsets'].apply(lambda x: ', '.join(x))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:40:00.528468Z",
          "iopub.execute_input": "2021-09-11T12:40:00.529204Z",
          "iopub.status.idle": "2021-09-11T12:40:00.619255Z",
          "shell.execute_reply.started": "2021-09-11T12:40:00.528804Z",
          "shell.execute_reply": "2021-09-11T12:40:00.618375Z"
        },
        "trusted": true,
        "id": "sE62UIS5x29K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.bar(label_combi_fp_df, x=\"support\", y=\"itemsets\", orientation='h', \\\n",
        "            title='Frequent Patterns of The Cloud Formation')\n",
        "fig.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:40:00.624697Z",
          "iopub.execute_input": "2021-09-11T12:40:00.625048Z",
          "iopub.status.idle": "2021-09-11T12:40:01.17567Z",
          "shell.execute_reply.started": "2021-09-11T12:40:00.624987Z",
          "shell.execute_reply": "2021-09-11T12:40:01.174292Z"
        },
        "trusted": true,
        "id": "LKvN2kZdx29K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sugar cloud formation frequently appears together in the images with Gravel or Fish cloud formation. Sugar also appears with Flower cloud formation but is less frequent. Gravels and Fish cloud formation also appears with other cloud formation. Sugar, Gravel, and Fish also appears all together in some instances.\n",
        "\n",
        "Flower tends to occur less frequently with other clouds, and the combination of Gravel and Flower occurs but at much less frequency compared to others. In fact, Sugar, Gravel, and Fish appear all together more frequently than Grave and Flower. However, it's not like Flower cloud formation never occurs with other cloud formation, just occurs less frequently compared to others.\n",
        "\n",
        "In summary, they are all combination of cloud formations appearing together is a possibility, and the combinations between Sugar, Fish, and Gravel are more likely than with Flower cloud formation."
      ],
      "metadata": {
        "id": "slVVTjjGx29K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Augmentation"
      ],
      "metadata": {
        "id": "gj9jhK0dx29K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_name = '8242ba0.jpg'\n",
        "image = get_img(image_name)\n",
        "mask = make_mask(train, image_name)\n",
        "visualize(image, mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:40:01.177925Z",
          "iopub.execute_input": "2021-09-11T12:40:01.178682Z",
          "iopub.status.idle": "2021-09-11T12:40:02.948814Z",
          "shell.execute_reply.started": "2021-09-11T12:40:01.178348Z",
          "shell.execute_reply": "2021-09-11T12:40:02.947642Z"
        },
        "trusted": true,
        "id": "CehxAgsXx29K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_with_augmentation(image, mask, albu.HorizontalFlip(p=1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:40:02.950749Z",
          "iopub.execute_input": "2021-09-11T12:40:02.95144Z",
          "iopub.status.idle": "2021-09-11T12:40:06.115553Z",
          "shell.execute_reply.started": "2021-09-11T12:40:02.951356Z",
          "shell.execute_reply": "2021-09-11T12:40:06.114543Z"
        },
        "trusted": true,
        "id": "CTEX_aypx29L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_with_augmentation(image, mask, albu.VerticalFlip(p=1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:40:06.117587Z",
          "iopub.execute_input": "2021-09-11T12:40:06.118309Z",
          "iopub.status.idle": "2021-09-11T12:40:09.151623Z",
          "shell.execute_reply.started": "2021-09-11T12:40:06.117916Z",
          "shell.execute_reply": "2021-09-11T12:40:09.150708Z"
        },
        "trusted": true,
        "id": "P36RwLH0x29L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_with_augmentation(image, mask, albu.RandomRotate90(p=1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:41:04.875632Z",
          "iopub.execute_input": "2021-09-11T12:41:04.876025Z",
          "iopub.status.idle": "2021-09-11T12:41:07.784492Z",
          "shell.execute_reply.started": "2021-09-11T12:41:04.875962Z",
          "shell.execute_reply": "2021-09-11T12:41:07.782948Z"
        },
        "trusted": true,
        "id": "c6LjnRAFx29L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_with_augmentation(image, mask, albu.ElasticTransform(p=1, alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-11T12:40:12.206124Z",
          "iopub.execute_input": "2021-09-11T12:40:12.2066Z",
          "iopub.status.idle": "2021-09-11T12:40:15.932525Z",
          "shell.execute_reply.started": "2021-09-11T12:40:12.206545Z",
          "shell.execute_reply": "2021-09-11T12:40:15.930899Z"
        },
        "trusted": true,
        "id": "vEZLDRfcx29L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resize images"
      ],
      "metadata": {
        "id": "W6UCyAfix29L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The task of this work is to predict mask for unseen (test) images. Is also requested that the mask should be scaled down to 350 x 525 px; but the images are of dimension 1400 x 2100 px. We decided to resize the dataset before hand so that we do not need to do this repetitively for each epoch. To do this we just upload a different dateset, made by a Kaggle user, where the resize of the images was already done. This strategy speed up the learning (avoiding to resize the images at each epoch) and also resolve an error related to exceeding memory usage.\n"
      ],
      "metadata": {
        "id": "3G8zgQpox29L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RES_IMG_PATH = '../input/understanding-clouds-resized'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:39:59.646067Z",
          "iopub.execute_input": "2021-09-09T13:39:59.646502Z",
          "iopub.status.idle": "2021-09-09T13:39:59.650709Z",
          "shell.execute_reply.started": "2021-09-09T13:39:59.646334Z",
          "shell.execute_reply": "2021-09-09T13:39:59.649599Z"
        },
        "trusted": true,
        "id": "PFRS8_sPx29L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "btoekElTx29M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make a split in order to have a validation set for train images** \n"
      ],
      "metadata": {
        "id": "xwJX2NdJx29M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(TRAIN_CSV_PATH)\n",
        "train[\"label\"] = train[\"Image_Label\"].apply(lambda x: x.split(\"_\")[1])\n",
        "train[\"im_id\"] = train[\"Image_Label\"].apply(lambda x: x.split(\"_\")[0])\n",
        "\n",
        "sub = pd.read_csv(f\"{DATA_PATH}/sample_submission.csv\")\n",
        "sub[\"label\"] = sub[\"Image_Label\"].apply(lambda x: x.split(\"_\")[1])\n",
        "sub[\"im_id\"] = sub[\"Image_Label\"].apply(lambda x: x.split(\"_\")[0])\n",
        "\n",
        "# split data\n",
        "id_mask_count = (\n",
        "    train.loc[train[\"EncodedPixels\"].isnull() == False, \"Image_Label\"]\n",
        "    .apply(lambda x: x.split(\"_\")[0])\n",
        "    .value_counts()\n",
        "    .sort_index()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"index\": \"img_id\", \"Image_Label\": \"count\"})\n",
        ")\n",
        "ids = id_mask_count[\"img_id\"].values\n",
        "li = [\n",
        "    [train_index, test_index]\n",
        "    for train_index, test_index in StratifiedKFold(\n",
        "        n_splits=N_FOLDS, random_state=SEED\n",
        "    ).split(ids, id_mask_count[\"count\"])\n",
        "]\n",
        "train_ids, valid_ids = ids[li[MODEL_NO][0]], ids[li[MODEL_NO][1]]\n",
        "test_ids = sub[\"Image_Label\"].apply(lambda x: x.split(\"_\")[0]).drop_duplicates().values\n",
        "\n",
        "print(f\"training set length: {len(train_ids)}\")\n",
        "print(f\"validation set length: {len(valid_ids)}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:39:59.652189Z",
          "iopub.execute_input": "2021-09-09T13:39:59.652711Z",
          "iopub.status.idle": "2021-09-09T13:40:01.838773Z",
          "shell.execute_reply.started": "2021-09-09T13:39:59.652438Z",
          "shell.execute_reply": "2021-09-09T13:40:01.83792Z"
        },
        "trusted": true,
        "id": "hkBFX3Xlx29M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class\n",
        "class CloudDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        df: pd.DataFrame = None,\n",
        "        datatype: str = \"train\",\n",
        "        img_ids: np.array = None,\n",
        "        transforms=albu.Compose([albu.HorizontalFlip()]), #, AT.ToTensor() ################### NEED TO BE CHECKED ###############Ã \n",
        "    ):\n",
        "        self.df = df\n",
        "        if datatype != \"test\":\n",
        "            self.data_folder = f\"{RES_IMG_PATH}/train_images_525/train_images_525\"\n",
        "        else:\n",
        "            self.data_folder = f\"{RES_IMG_PATH}/test_images_525/test_images_525\"\n",
        "        self.img_ids = img_ids\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.img_ids[idx]\n",
        "        mask = make_mask(self.df, image_name)\n",
        "        image_path = os.path.join(self.data_folder, image_name)\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        augmented = self.transforms(image=img, mask=mask)\n",
        "        img = np.transpose(augmented[\"image\"], [2, 0, 1])\n",
        "        mask = np.transpose(augmented[\"mask\"], [2, 0, 1])\n",
        "        return img, mask\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_ids)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:01.839989Z",
          "iopub.execute_input": "2021-09-09T13:40:01.840281Z",
          "iopub.status.idle": "2021-09-09T13:40:01.850859Z",
          "shell.execute_reply.started": "2021-09-09T13:40:01.840235Z",
          "shell.execute_reply": "2021-09-09T13:40:01.850108Z"
        },
        "trusted": true,
        "id": "P60Vybdzx29M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define dataset and dataloader\n",
        "num_workers = 2\n",
        "bs = 8\n",
        "train_dataset = CloudDataset(\n",
        "    df=train,\n",
        "    datatype=\"train\",\n",
        "    img_ids=train_ids,\n",
        "    transforms=get_training_augmentation(),\n",
        ")\n",
        "valid_dataset = CloudDataset(\n",
        "    df=train,\n",
        "    datatype=\"valid\",\n",
        "    img_ids=valid_ids,\n",
        "    transforms=get_validation_augmentation(),\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, batch_size=bs, shuffle=True, num_workers=num_workers\n",
        ")\n",
        "valid_loader = DataLoader(\n",
        "    valid_dataset, batch_size=bs, shuffle=False, num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:01.852351Z",
          "iopub.execute_input": "2021-09-09T13:40:01.852899Z",
          "iopub.status.idle": "2021-09-09T13:40:01.865849Z",
          "shell.execute_reply.started": "2021-09-09T13:40:01.85285Z",
          "shell.execute_reply": "2021-09-09T13:40:01.865031Z"
        },
        "trusted": true,
        "id": "D5LWfegJx29N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model definition"
      ],
      "metadata": {
        "id": "nwAjJZK2x29N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class double_conv(nn.Module):\n",
        "    \"\"\"(conv => BN => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(nn.MaxPool2d(2), double_conv(in_ch, out_ch))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=True):\n",
        "        super(up, self).__init__()\n",
        "\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_ch // 2, in_ch // 2, 2, stride=2)\n",
        "\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2))\n",
        "        \n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.inc = inconv(n_channels, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 512)\n",
        "        self.up1 = up(1024, 256, False)\n",
        "        self.up2 = up(512, 128, False)\n",
        "        self.up3 = up(256, 64, False)\n",
        "        self.up4 = up(128, 64, False)\n",
        "        self.outc = outconv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:01.8676Z",
          "iopub.execute_input": "2021-09-09T13:40:01.868247Z",
          "iopub.status.idle": "2021-09-09T13:40:01.895866Z",
          "shell.execute_reply.started": "2021-09-09T13:40:01.867954Z",
          "shell.execute_reply": "2021-09-09T13:40:01.894966Z"
        },
        "trusted": true,
        "id": "k1PryTM7x29N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet(n_channels=3, n_classes=4).float()\n",
        "if train_on_gpu:\n",
        "    model.cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:01.897238Z",
          "iopub.execute_input": "2021-09-09T13:40:01.897645Z",
          "iopub.status.idle": "2021-09-09T13:40:05.9183Z",
          "shell.execute_reply.started": "2021-09-09T13:40:01.897475Z",
          "shell.execute_reply": "2021-09-09T13:40:05.917379Z"
        },
        "trusted": true,
        "id": "2hgZ24vIx29N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model # print Model\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:05.919746Z",
          "iopub.execute_input": "2021-09-09T13:40:05.920037Z",
          "iopub.status.idle": "2021-09-09T13:40:05.929439Z",
          "shell.execute_reply.started": "2021-09-09T13:40:05.919991Z",
          "shell.execute_reply": "2021-09-09T13:40:05.928472Z"
        },
        "trusted": true,
        "id": "UoKzM9spx29N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shallow model"
      ],
      "metadata": {
        "id": "BH-Fid-Gx29O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Shallow_UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(Shallow_UNet, self).__init__()\n",
        "        self.inc = inconv(n_channels, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 256)\n",
        "        self.up1 = up(512, 128, False)\n",
        "        self.up2 = up(256, 64, False)\n",
        "        self.up3 = up(128, 64, False)\n",
        "        self.outc = outconv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x = self.up1(x4, x3)\n",
        "        x = self.up2(x, x2)\n",
        "        x = self.up3(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:05.931138Z",
          "iopub.execute_input": "2021-09-09T13:40:05.931625Z",
          "iopub.status.idle": "2021-09-09T13:40:05.944098Z",
          "shell.execute_reply.started": "2021-09-09T13:40:05.931433Z",
          "shell.execute_reply": "2021-09-09T13:40:05.943265Z"
        },
        "trusted": true,
        "id": "QNBuJx3lx29O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shallow_model = Shallow_UNet(n_channels=3, n_classes=4).float()\n",
        "#if train_on_gpu:\n",
        "#    model.cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:05.947672Z",
          "iopub.execute_input": "2021-09-09T13:40:05.947896Z",
          "iopub.status.idle": "2021-09-09T13:40:05.981958Z",
          "shell.execute_reply.started": "2021-09-09T13:40:05.947855Z",
          "shell.execute_reply": "2021-09-09T13:40:05.981237Z"
        },
        "trusted": true,
        "id": "aLntB_kTx29O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shallow_model # print Model\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:05.98313Z",
          "iopub.execute_input": "2021-09-09T13:40:05.983413Z",
          "iopub.status.idle": "2021-09-09T13:40:05.989369Z",
          "shell.execute_reply.started": "2021-09-09T13:40:05.983371Z",
          "shell.execute_reply": "2021-09-09T13:40:05.988556Z"
        },
        "trusted": true,
        "id": "ELAGm6Tex29O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deeper model"
      ],
      "metadata": {
        "id": "oOUqsIs6x29O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Deeper_UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(Deeper_UNet, self).__init__()\n",
        "        self.inc = inconv(n_channels, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 1024)\n",
        "        self.down5 = down(1024, 1024)\n",
        "        self.up1 = up(2048, 512, False)\n",
        "        self.up2 = up(1024, 256, False)\n",
        "        self.up3 = up(512, 128, False)\n",
        "        self.up4 = up(256, 64, False)\n",
        "        self.up5 = up(128, 64, False)\n",
        "        self.outc = outconv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x6 = self.down5(x5)\n",
        "        x = self.up1(x6, x5)\n",
        "        x = self.up2(x, x4)\n",
        "        x = self.up3(x, x3)\n",
        "        x = self.up4(x, x2)\n",
        "        x = self.up5(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:05.990852Z",
          "iopub.execute_input": "2021-09-09T13:40:05.991395Z",
          "iopub.status.idle": "2021-09-09T13:40:06.005583Z",
          "shell.execute_reply.started": "2021-09-09T13:40:05.991346Z",
          "shell.execute_reply": "2021-09-09T13:40:06.004786Z"
        },
        "trusted": true,
        "id": "oEaR-ImFx29O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deeper_model = Deeper_UNet(n_channels=3, n_classes=4).float()\n",
        "#if train_on_gpu:\n",
        "#    model.cuda()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:06.006875Z",
          "iopub.execute_input": "2021-09-09T13:40:06.007445Z",
          "iopub.status.idle": "2021-09-09T13:40:06.419232Z",
          "shell.execute_reply.started": "2021-09-09T13:40:06.007202Z",
          "shell.execute_reply": "2021-09-09T13:40:06.418335Z"
        },
        "trusted": true,
        "id": "KJiiNW5Fx29O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deeper_model # print Model\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:06.420525Z",
          "iopub.execute_input": "2021-09-09T13:40:06.42082Z",
          "iopub.status.idle": "2021-09-09T13:40:06.429246Z",
          "shell.execute_reply.started": "2021-09-09T13:40:06.420775Z",
          "shell.execute_reply": "2021-09-09T13:40:06.428239Z"
        },
        "trusted": true,
        "id": "iCqwk0ulx29P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the optimizer (RAdam)"
      ],
      "metadata": {
        "id": "9yUoR8O_x29P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "\n",
        "class RAdam(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "            \n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        self.buffer = [[None, None, None] for ind in range(10)]\n",
        "        super(RAdam, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(RAdam, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "\n",
        "                state['step'] += 1\n",
        "                buffered = self.buffer[int(state['step'] % 10)]\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, step_size = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "\n",
        "                    # more conservative since it's an approximated value\n",
        "                    if N_sma >= 5:\n",
        "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
        "                    buffered[2] = step_size\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
        "\n",
        "                # more conservative since it's an approximated value\n",
        "                if N_sma >= 5:            \n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
        "                else:\n",
        "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
        "\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:06.430783Z",
          "iopub.execute_input": "2021-09-09T13:40:06.431342Z",
          "iopub.status.idle": "2021-09-09T13:40:06.459432Z",
          "shell.execute_reply.started": "2021-09-09T13:40:06.431106Z",
          "shell.execute_reply": "2021-09-09T13:40:06.458762Z"
        },
        "trusted": true,
        "id": "VwYtpNgfx29P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the loss function"
      ],
      "metadata": {
        "id": "1MRJ7hSPx29P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f_score(pr, gt, beta=1, eps=1e-7, threshold=None, activation='sigmoid'):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        pr (torch.Tensor): A list of predicted elements\n",
        "        gt (torch.Tensor):  A list of elements that are to be predicted\n",
        "        eps (float): epsilon to avoid zero division\n",
        "        threshold: threshold for outputs binarization\n",
        "    Returns:\n",
        "        float: IoU (Jaccard) score\n",
        "    \"\"\"\n",
        "\n",
        "    if activation is None or activation == \"none\":\n",
        "        activation_fn = lambda x: x\n",
        "    elif activation == \"sigmoid\":\n",
        "        activation_fn = torch.nn.Sigmoid()\n",
        "    elif activation == \"softmax2d\":\n",
        "        activation_fn = torch.nn.Softmax2d()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            \"Activation implemented for sigmoid and softmax2d\"\n",
        "        )\n",
        "\n",
        "    pr = activation_fn(pr)\n",
        "\n",
        "    if threshold is not None:\n",
        "        pr = (pr > threshold).float()\n",
        "\n",
        "\n",
        "    tp = torch.sum(gt * pr)\n",
        "    fp = torch.sum(pr) - tp\n",
        "    fn = torch.sum(gt) - tp\n",
        "\n",
        "    score = ((1 + beta ** 2) * tp + eps) \\\n",
        "            / ((1 + beta ** 2) * tp + beta ** 2 * fn + fp + eps)\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    __name__ = 'dice_loss'\n",
        "\n",
        "    def __init__(self, eps=1e-7, activation='sigmoid'):\n",
        "        super().__init__()\n",
        "        self.activation = activation\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, y_pr, y_gt):\n",
        "        return 1 - f_score(y_pr, y_gt, beta=1., \n",
        "                           eps=self.eps, threshold=None, \n",
        "                           activation=self.activation)\n",
        "\n",
        "\n",
        "class BCEDiceLoss(DiceLoss):\n",
        "    __name__ = 'bce_dice_loss'\n",
        "\n",
        "    def __init__(self, eps=1e-7, activation='sigmoid', lambda_dice=1.0, lambda_bce=1.0):\n",
        "        super().__init__(eps, activation)\n",
        "        if activation == None:\n",
        "            self.bce = nn.BCELoss(reduction='mean')\n",
        "        else:\n",
        "            self.bce = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "        self.lambda_dice=lambda_dice\n",
        "        self.lambda_bce=lambda_bce\n",
        "\n",
        "    def forward(self, y_pr, y_gt):\n",
        "        dice = super().forward(y_pr, y_gt)\n",
        "        bce = self.bce(y_pr, y_gt)\n",
        "        return (self.lambda_dice*dice) + (self.lambda_bce* bce)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:06.460656Z",
          "iopub.execute_input": "2021-09-09T13:40:06.460943Z",
          "iopub.status.idle": "2021-09-09T13:40:06.478395Z",
          "shell.execute_reply.started": "2021-09-09T13:40:06.460897Z",
          "shell.execute_reply": "2021-09-09T13:40:06.477208Z"
        },
        "trusted": true,
        "id": "B7znFzgux29P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training phase"
      ],
      "metadata": {
        "id": "wjSPw89bx29Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = BCEDiceLoss(eps=1.0, activation=None)\n",
        "optimizer = RAdam(model.parameters(), lr = 0.0005)\n",
        "current_lr = [param_group['lr'] for param_group in optimizer.param_groups][0]\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.2, patience=2, cooldown=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:06.479795Z",
          "iopub.execute_input": "2021-09-09T13:40:06.480356Z",
          "iopub.status.idle": "2021-09-09T13:40:06.492001Z",
          "shell.execute_reply.started": "2021-09-09T13:40:06.480145Z",
          "shell.execute_reply": "2021-09-09T13:40:06.491408Z"
        },
        "trusted": true,
        "id": "TiSxgWKfx29Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 25\n",
        "train_loss_list = []\n",
        "valid_loss_list = []\n",
        "dice_score_list = []\n",
        "lr_rate_list = []\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    dice_score = 0.0\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    bar = tq(train_loader, postfix={\"train_loss\":0.0})\n",
        "    for data, target in bar:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        #print(loss)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        bar.set_postfix(ordered_dict={\"train_loss\":loss.item()})\n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    del data, target\n",
        "    with torch.no_grad():\n",
        "        bar = tq(valid_loader, postfix={\"valid_loss\":0.0, \"dice_score\":0.0})\n",
        "        for data, target in bar:\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            if train_on_gpu:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            output = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(output, target)\n",
        "            # update average validation loss \n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "            dice_cof = dice_no_threshold(output.cpu(), target.cpu()).item()\n",
        "            dice_score +=  dice_cof * data.size(0)\n",
        "            bar.set_postfix(ordered_dict={\"valid_loss\":loss.item(), \"dice_score\":dice_cof})\n",
        "    \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "    dice_score = dice_score/len(valid_loader.dataset)\n",
        "    train_loss_list.append(train_loss)\n",
        "    valid_loss_list.append(valid_loss)\n",
        "    dice_score_list.append(dice_score)\n",
        "    lr_rate_list.append([param_group['lr'] for param_group in optimizer.param_groups])\n",
        "    \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {}  Training Loss: {:.6f}  Validation Loss: {:.6f} Dice Score: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss, dice_score))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model_cifar.pt')\n",
        "        valid_loss_min = valid_loss\n",
        "    \n",
        "    scheduler.step(valid_loss)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T13:40:06.493234Z",
          "iopub.execute_input": "2021-09-09T13:40:06.49361Z",
          "iopub.status.idle": "2021-09-09T16:47:18.930283Z",
          "shell.execute_reply.started": "2021-09-09T13:40:06.493528Z",
          "shell.execute_reply": "2021-09-09T16:47:18.929552Z"
        },
        "trusted": true,
        "id": "LDVZ_92ex29Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### metrics"
      ],
      "metadata": {
        "id": "Gj1zwJLvx29Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot([i[0] for i in lr_rate_list])\n",
        "plt.ylabel('learing rate during training', fontsize=22)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:47:18.931812Z",
          "iopub.execute_input": "2021-09-09T16:47:18.932106Z",
          "iopub.status.idle": "2021-09-09T16:47:19.182497Z",
          "shell.execute_reply.started": "2021-09-09T16:47:18.932054Z",
          "shell.execute_reply": "2021-09-09T16:47:19.181802Z"
        },
        "trusted": true,
        "id": "l_IfQHu9x29Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(train_loss_list,  marker='o', label=\"Training Loss\")\n",
        "plt.plot(valid_loss_list,  marker='o', label=\"Validation Loss\")\n",
        "plt.ylabel('loss', fontsize=22)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2021-09-09T16:47:19.18373Z",
          "iopub.execute_input": "2021-09-09T16:47:19.184145Z",
          "iopub.status.idle": "2021-09-09T16:47:19.473532Z",
          "shell.execute_reply.started": "2021-09-09T16:47:19.184097Z",
          "shell.execute_reply": "2021-09-09T16:47:19.472598Z"
        },
        "trusted": true,
        "id": "972AV-Fjx29Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(dice_score_list)\n",
        "plt.ylabel('Dice score', fontsize=22)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:47:19.477796Z",
          "iopub.execute_input": "2021-09-09T16:47:19.478226Z",
          "iopub.status.idle": "2021-09-09T16:47:19.751888Z",
          "shell.execute_reply.started": "2021-09-09T16:47:19.478044Z",
          "shell.execute_reply": "2021-09-09T16:47:19.750933Z"
        },
        "trusted": true,
        "id": "IPmNOokLx29R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load best model\n",
        "model.load_state_dict(torch.load('model_cifar.pt'))\n",
        "model.eval();"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:47:19.756274Z",
          "iopub.execute_input": "2021-09-09T16:47:19.758536Z",
          "iopub.status.idle": "2021-09-09T16:47:19.815794Z",
          "shell.execute_reply.started": "2021-09-09T16:47:19.756523Z",
          "shell.execute_reply": "2021-09-09T16:47:19.815186Z"
        },
        "trusted": true,
        "id": "HmvvtbXFx29R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_masks = []\n",
        "count = 0\n",
        "tr = min(len(valid_ids)*4, 2000)\n",
        "probabilities = np.zeros((tr, 350, 525), dtype = np.float32)\n",
        "for data, target in tq(valid_loader):\n",
        "    if train_on_gpu:\n",
        "        data = data.cuda()\n",
        "    target = target.cpu().detach().numpy()\n",
        "    outpu = model(data).cpu().detach().numpy()\n",
        "    for p in range(data.shape[0]):\n",
        "        output, mask = outpu[p], target[p]\n",
        "        for m in mask:\n",
        "            valid_masks.append(resize_it(m))\n",
        "        for probability in output:\n",
        "            probabilities[count, :, :] = resize_it(probability)\n",
        "            count += 1\n",
        "        if count >= tr - 1:\n",
        "            break\n",
        "    if count >= tr - 1:\n",
        "        break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:47:19.818213Z",
          "iopub.execute_input": "2021-09-09T16:47:19.818643Z",
          "iopub.status.idle": "2021-09-09T16:47:42.402132Z",
          "shell.execute_reply.started": "2021-09-09T16:47:19.818591Z",
          "shell.execute_reply": "2021-09-09T16:47:42.401408Z"
        },
        "trusted": true,
        "id": "cje9H7SDx29R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grid Search in order to find the best parameters\n"
      ],
      "metadata": {
        "id": "wJRqOn-sx29R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_params = {}\n",
        "for class_id in range(4):\n",
        "    print(class_id)\n",
        "    attempts = []\n",
        "    for t in range(10, 90, 5):\n",
        "        t /= 100\n",
        "        for ms in [5000, 10000, 20000, 30000, 40000]:\n",
        "            masks, d = [], []\n",
        "            for i in range(class_id, len(probabilities), 4):\n",
        "                probability = probabilities[i]\n",
        "                predict, num_predict = post_process(probability, t, ms)\n",
        "                masks.append(predict)\n",
        "            for i, j in zip(masks, valid_masks[class_id::4]):\n",
        "                if (i.sum() == 0) & (j.sum() == 0):\n",
        "                    d.append(1)\n",
        "                else:\n",
        "                    d.append(dice(i, j))\n",
        "            attempts.append((t, ms, np.mean(d)))\n",
        "\n",
        "    attempts_df = pd.DataFrame(attempts, columns=['threshold', 'size', 'dice'])\n",
        "    attempts_df = attempts_df.sort_values('dice', ascending=False)\n",
        "    print(attempts_df.head())\n",
        "    best_threshold = attempts_df['threshold'].values[0]\n",
        "    best_size = attempts_df['size'].values[0]\n",
        "    class_params[class_id] = (best_threshold, best_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:47:42.405347Z",
          "iopub.execute_input": "2021-09-09T16:47:42.405585Z",
          "iopub.status.idle": "2021-09-09T16:58:31.549193Z",
          "shell.execute_reply.started": "2021-09-09T16:47:42.405535Z",
          "shell.execute_reply": "2021-09-09T16:58:31.548485Z"
        },
        "trusted": true,
        "id": "btLm92eLx29R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attempts_df = pd.DataFrame(attempts, columns=['threshold', 'size', 'dice'])\n",
        "print(class_params)\n",
        "#attempts_df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:58:31.551094Z",
          "iopub.execute_input": "2021-09-09T16:58:31.551589Z",
          "iopub.status.idle": "2021-09-09T16:58:31.558104Z",
          "shell.execute_reply.started": "2021-09-09T16:58:31.551536Z",
          "shell.execute_reply": "2021-09-09T16:58:31.557379Z"
        },
        "trusted": true,
        "id": "wEiN98OYx29R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del masks\n",
        "del valid_masks\n",
        "del probabilities\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:58:31.55943Z",
          "iopub.execute_input": "2021-09-09T16:58:31.559863Z",
          "iopub.status.idle": "2021-09-09T16:58:31.737224Z",
          "shell.execute_reply.started": "2021-09-09T16:58:31.559816Z",
          "shell.execute_reply": "2021-09-09T16:58:31.736278Z"
        },
        "trusted": true,
        "id": "HIykkjOOx29S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicted masks on validation set"
      ],
      "metadata": {
        "id": "HlrwWaspx29S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (data, target) in enumerate(valid_loader):\n",
        "    if train_on_gpu:\n",
        "        data = data.cuda()\n",
        "    output = ((model(data))[0]).cpu().detach().numpy()\n",
        "    image  = data[0].cpu().detach().numpy()\n",
        "    mask   = target[0].cpu().detach().numpy()\n",
        "    output = output.transpose(1 ,2, 0)\n",
        "    image_vis = image.transpose(1, 2, 0)\n",
        "    mask = mask.astype('uint8').transpose(1, 2, 0)\n",
        "    pr_mask = np.zeros((350, 525, 4))\n",
        "    for j in range(4):\n",
        "        probability = resize_it(output[:, :, j])\n",
        "        pr_mask[:, :, j], _ = post_process(probability,\n",
        "                                           class_params[j][0],\n",
        "                                           class_params[j][1])\n",
        "    visualize_with_raw(image=image_vis, mask=pr_mask,\n",
        "                      original_image=image_vis, original_mask=mask,\n",
        "                      raw_image=image_vis, raw_mask=output)\n",
        "    if i >= 6:\n",
        "        break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:58:31.738734Z",
          "iopub.execute_input": "2021-09-09T16:58:31.739148Z",
          "iopub.status.idle": "2021-09-09T16:58:54.037947Z",
          "shell.execute_reply.started": "2021-09-09T16:58:31.739099Z",
          "shell.execute_reply": "2021-09-09T16:58:54.037082Z"
        },
        "trusted": true,
        "id": "1b3DYtgWx29S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "del train_dataset, train_loader\n",
        "del valid_dataset, valid_loader\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:58:54.039406Z",
          "iopub.execute_input": "2021-09-09T16:58:54.03985Z",
          "iopub.status.idle": "2021-09-09T16:58:54.543663Z",
          "shell.execute_reply.started": "2021-09-09T16:58:54.039672Z",
          "shell.execute_reply": "2021-09-09T16:58:54.542899Z"
        },
        "trusted": true,
        "id": "pBFSMLIFx29S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CloudDataset(df=sub,\n",
        "                            datatype='test', \n",
        "                            img_ids=test_ids,\n",
        "                            transforms=get_validation_augmentation())\n",
        "test_loader = DataLoader(test_dataset, batch_size=4,\n",
        "                         shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:58:54.545096Z",
          "iopub.execute_input": "2021-09-09T16:58:54.549821Z",
          "iopub.status.idle": "2021-09-09T16:58:54.555542Z",
          "shell.execute_reply.started": "2021-09-09T16:58:54.54977Z",
          "shell.execute_reply": "2021-09-09T16:58:54.554865Z"
        },
        "trusted": true,
        "id": "q-UIs0PNx29S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission"
      ],
      "metadata": {
        "id": "nL-vkLN-x29S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subm = pd.read_csv(\"../input/understanding_cloud_organization/sample_submission.csv\")\n",
        "pathlist = [\"../input/understanding_cloud_organization/test_images/\" + i.split(\"_\")[0] for i in subm['Image_Label']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:58:54.556862Z",
          "iopub.execute_input": "2021-09-09T16:58:54.557391Z",
          "iopub.status.idle": "2021-09-09T16:58:54.594925Z",
          "shell.execute_reply.started": "2021-09-09T16:58:54.557341Z",
          "shell.execute_reply": "2021-09-09T16:58:54.594278Z"
        },
        "trusted": true,
        "id": "1O_utj29x29S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_black_mask(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (525,350))\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    lower = np.array([0, 0, 0], np.uint8)\n",
        "    upper = np.array([180, 255, 10], np.uint8)\n",
        "    return (~ (cv2.inRange(hsv, lower, upper) > 250)).astype(int)\n",
        "\n",
        "plt.imshow(get_black_mask(pathlist[120]))\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:58:54.598744Z",
          "iopub.execute_input": "2021-09-09T16:58:54.600824Z",
          "iopub.status.idle": "2021-09-09T16:58:55.008503Z",
          "shell.execute_reply.started": "2021-09-09T16:58:54.600773Z",
          "shell.execute_reply": "2021-09-09T16:58:55.007794Z"
        },
        "trusted": true,
        "id": "0GZS23VIx29T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_pixels = []\n",
        "image_id = 0\n",
        "cou = 0\n",
        "np_saved = 0\n",
        "for data, target in tq(test_loader):\n",
        "    if train_on_gpu:\n",
        "        data = data.cuda()\n",
        "    output = model(data)\n",
        "    del data\n",
        "    for i, batch in enumerate(output):\n",
        "        for probability in batch:\n",
        "            probability = resize_it(probability.cpu().detach().numpy())\n",
        "            predict, num_predict = post_process(probability,\n",
        "                                                class_params[image_id % 4][0],\n",
        "                                                class_params[image_id % 4][1])\n",
        "            if num_predict == 0:\n",
        "                encoded_pixels.append('')\n",
        "            else:\n",
        "                black_mask = get_black_mask(pathlist[cou])\n",
        "                np_saved += np.sum(predict)\n",
        "                predict = np.multiply(predict, black_mask)\n",
        "                np_saved -= np.sum(predict)\n",
        "                r = mask2rle(predict)\n",
        "                encoded_pixels.append(r)\n",
        "            cou += 1\n",
        "            image_id += 1\n",
        "\n",
        "print(f\"number of pixel saved {np_saved}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T16:58:55.012915Z",
          "iopub.execute_input": "2021-09-09T16:58:55.016199Z",
          "iopub.status.idle": "2021-09-09T17:06:27.715641Z",
          "shell.execute_reply.started": "2021-09-09T16:58:55.016136Z",
          "shell.execute_reply": "2021-09-09T17:06:27.712511Z"
        },
        "trusted": true,
        "id": "GcrHXO1Ix29T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub['EncodedPixels'] = encoded_pixels\n",
        "sub.to_csv('submission.csv', columns=['Image_Label', 'EncodedPixels'], index=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-09T17:06:27.721426Z",
          "iopub.execute_input": "2021-09-09T17:06:27.722277Z",
          "iopub.status.idle": "2021-09-09T17:06:30.492013Z",
          "shell.execute_reply.started": "2021-09-09T17:06:27.722185Z",
          "shell.execute_reply": "2021-09-09T17:06:30.491237Z"
        },
        "trusted": true,
        "id": "xTA4y3O1x29T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}